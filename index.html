<!doctype html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7" lang=""> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8" lang=""> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9" lang=""> <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="">
<!--<![endif]-->
<head>
<meta charset="utf-8">
<meta name="description" content="">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Felix Kreuk</title>
<link rel="stylesheet" href="css/bootstrap.min.css">
<link rel="stylesheet" href="css/flexslider.css">
<link rel="stylesheet" href="css/jquery.fancybox.css">
<link rel="stylesheet" href="css/main.css">
<link rel="stylesheet" href="css/responsive.css">
<link rel="stylesheet" href="css/animate.min.css">
<link rel="stylesheet" href="css/font-icon.css">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
<link href="css/academicons/css/academicons.min.css" rel="stylesheet">
</head>
<body>
<!-- header top section -->
<section class="banner" role="banner">
  <header id="header">
    <div class="header-content clearfix">
      <nav class="navigation" role="navigation">
        <ul class="primary-nav">
          <li><a href="#home">Home</a></li>
          <li><a href="#publications">Publications</a></li>
        </ul>
      </nav>
      <a href="#" class="nav-toggle">Menu<span></span></a> </div>
  </header>
</section>

<!-- header top section --> 
<!-- header content section -->
<section id="hero" class="section ">
  <div class="container">
    <div class="row">
      <div class="col-md-5 col-sm-6 hero">
        <div class="hero-content">
          <img class="img-fluid img-profile rounded-circle mx-auto mb-2" width="400" src="images/felix.jpeg" alt="">
          <h2>Felix Kreuk</h2>
        </div>
        <!-- hero --> 
      </div>
      <div class="col-md-7 col-sm-6 hero">
        <div class="hero-content">
          <p>
            My name is Felix Kreuk. 
            I am currently a Research Engineer at Meta AI research, previously Facebook AI Research (FAIR). 
            I completed my PhD in Computer-Science from <a href="https://www.biu.ac.il/en">Bar-Ilan University</a> under the supervision of <a href="https://keshet.net.technion.ac.il/">Prof. Joseph Keshet</a>. 
            I have also spent time at NVIDIA Research (2019-2020).
            <br/><br/>
            My research interests lie in the intersection of deep-learning and speech/audio processing. 
            Most of my recent work involves with generative models for speech and general audio.
          </p>

          <br>
          <i class="fa fa-envelope"></i> felix.kreuk at gmail dot com</a>

          <br><br>
          <a href="https://github.com/felixkreuk" target="_blank" class="social">
            <span class="fa-stack fa-lg">
              <i class="fa fa-circle fa-stack-2x"></i>
              <i class="fa fa-github fa-stack-1x fa-inverse"></i>
            </span>
          </a>
          <a href="https://scholar.google.co.il/citations?user=UiERcYsAAAAJ&hl=en" target="_blank" class="social">
            <span class="fa-stack fa-lg">
              <i class="fa fa-circle fa-stack-2x"></i>
              <i class="ai ai-google-scholar fa-stack-2x fa-inverse"></i>
            </span>
          </a>
          <a href="https://il.linkedin.com/in/felix-kreuk-033589b0" target="_blank" class="social">
            <span class="fa-stack fa-lg">
              <i class="fa fa-circle fa-stack-2x"></i>
              <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
            </span>
          </a>

        </div>
        <!-- hero --> 
      </div>
    </div>

    <div class="row">      
      <div class="col-md-12 text-left">
      	<h3><u>News</u></h3>	
    	  <ul class="fa-ul mb-0">
	  
	  <li class="mb-1">
            <i class="fa fa-li fa-book"></i>AudioGen was accepted to ICLR 2023!
          </li>
          
          <li class="mb-1">
            <i class="fa fa-li fa-newspaper-o"></i> AudioGen got some more attention: [<a href='https://the-decoder.com/audiogen-meta-ai-generates-audio-from-text/' target='blank'>The Decoder</a>].
          </li>
	  
          <li class="mb-1">
            <i class="fa fa-li fa-newspaper-o"></i> Our model AudioGen, which generates audio from textual descriptions got some attention from the media: [<a href='https://www.newscientist.com/article/2341416-metas-text-to-audio-ai-can-create-common-sounds-and-generate-music/' target='blank'>New Scientist</a>].
          </li>
          
          <li class="mb-1">
            <i class="fa fa-li fa-book"></i> Our research paper <a href='https://arxiv.org/pdf/2111.07402.pdf' target='blank'><em>Textless Speech Emotion Conversion using Decomposed and Discrete Representations</em></a> was accepted to EMNLP 2022!
          </li>
          
          <li class="mb-1">
            <i class="fa fa-li fa-microphone"></i> Our model AudioGen, was covered by Aleksa Gordić: [<a href='https://www.youtube.com/watch?v=RyIn-DxGF-c'>YouTube</a>].
          </li>
          
          <li class="mb-1">
            <i class="fa fa-li fa-book"></i> 4 papers accapted to INTERSPEECH 2022! More details in publications section.
          </li>
          
          <li class="mb-1">
            <i class="fa fa-li fa-book"></i> Our paper <a href='https://ieeexplore.ieee.org/document/9747953'><em>Speech Time-Scale Modification With GANs</em></a> was accapted to IEEE Signal Processing Letters 2022!
          </li>
          
          <li class="mb-1">
            <i class="fa fa-li fa-trophy"></i> Started as a full-time Research Engineer at Meta AI Research
          </li>
          
          <li class="mb-1">
            <i class="fa fa-li fa-microphone"></i> Invited talk at <a href='https://homepages.inf.ed.ac.uk/htang2/sigml/seminar/'>ISCA SIGML Seminar<a>, [<a href='https://www.youtube.com/watch?v=gk6thCWl_eE'>Video</a>].
          </li>
          
        </ul>
      </div>
    </div>
  </div>
</section>

<section id="publications" class="service section">
	<div class="container">
		<div class="row">
			<div class="col-md-12 text-left">
				<div class="my-auto">
          <h2 class="mb-5">Publications</h2>
          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <ol>
                
                <li id="paper"  class="mb-1"> <u>Felix Kreuk</u>, Gabriel Synnaeve, Adam Polyak, Uriel Singer, Alexandre Défossez, Jade Copet, Devi Parikh, Yaniv Taigman, Yossi Adi. <b>AudioGen: Textually Guided Audio Generation</b>. <em>arXiv, 2022</em> </li>
                  [
                  <a href="https://arxiv.org/pdf/2209.15352.pdf" target="_blank">PDF,</a>
                  
                  <a href="https://felixkreuk.github.io/audiogen/" target="_blank">Samples</a>
                  ]
                
                <li id="paper"  class="mb-1"> <u>Felix Kreuk</u>, Adam Polyak, Jade Copet, Eugene Kharitonov, Tu-Anh Nguyen, Morgane Rivière, Wei-Ning Hsu, Abdelrahman Mohamed Emmanuel Dupoux, Yossi Adi. <b>Textless Speech Emotion Conversion using Decomposed and Discrete Representations</b>. <em>Conference on Empirical Methods in Natural Language Processing (EMNLP), 2022</em> </li>
                  [
                  <a href="https://arxiv.org/pdf/2111.07402.pdf" target="_blank">PDF,</a>
                  
                  <a href="https://github.com/facebookresearch/fairseq/tree/main/examples/emotion_conversion" target="_blank">Code,</a>
                  
                  <a href="https://speechbot.github.io/emotion/" target="_blank">Samples,</a>
                  
                  <a href="https://ai.facebook.com/blog/generating-chit-chat-including-laughs-yawns-ums-and-other-nonverbal-cues-from-raw-audio/" target="_blank">Blog</a>
                  ]
                
                <li id="paper"  class="mb-1"> Or Tal, Moshe Mandel, <u>Felix Kreuk</u>, Yossi Adi. <b>A Systematic Comparison of Phonetic Aware Techniques for Speech Enhancement</b>. <em>The 23rd Annual Conference of the International Speech Communication Association (Interspeech), 2022</em> </li>
                  [
                  <a href="https://arxiv.org/pdf/2206.11000.pdf" target="_blank">PDF,</a>
                  
                  <a href="https://github.com/slp-rl/SC-PhASE" target="_blank">Code</a>
                  ]
                
                <li id="paper"  class="mb-1"> Yehoshua Dissen, <u>Felix Kreuk</u>, Joseph Keshet. <b>Self-supervised Speaker Diarization</b>. <em>The 23rd Annual Conference of the International Speech Communication Association (Interspeech), 2022</em> </li>
                  [
                  <a href="https://arxiv.org/pdf/2204.04166.pdf" target="_blank">PDF</a>
                  ]
                
                <li id="paper"  class="mb-1"> Yossi Shrem, <u>Felix Kreuk</u>, Joseph Keshet. <b>Formant Estimation and Tracking using Probabilistic Heat-Maps</b>. <em>The 23rd Annual Conference of the International Speech Communication Association (Interspeech), 2022</em> </li>
                  [
                  <a href="https://arxiv.org/pdf/2206.11632.pdf" target="_blank">PDF</a>
                  ]
                
                <li id="paper"  class="mb-1"> Talia Ben-Simon, <u>Felix Kreuk</u>, Faten Awwad, Jacob T. Cohen, Joseph Keshet. <b>Correcting Misproducted Speech using Spectrogram Inpainting</b>. <em>The 23rd Annual Conference of the International Speech Communication Association (Interspeech), 2022</em> </li>
                  [
                  <a href="https://arxiv.org/pdf/2204.03379.pdf" target="_blank">PDF</a>
                  ]
                
                <li id="paper"  class="mb-1"> Eyal Cohen, <u>Felix Kreuk</u>, Joseph Keshet. <b>Speech Time-Scale Modification With GANs</b>. <em>IEEE Signal Processing Letters, 2022</em> </li>
                  [
                  <a href="https://ieeexplore.ieee.org/document/9747953" target="_blank">PDF</a>
                  ]
                
                <li id="paper"  class="mb-1"> <u>Felix Kreuk</u>, Joseph Keshet, Yossi Adi. <b>Self-supervised contrastive learning for unsupervised phoneme segmentation</b>. <em>The 21st Annual Conference of the International Speech Communication Association (Interspeech), 2020</em> </li>
                  [
                  <a href="https://arxiv.org/pdf/2007.13465.pdf" target="_blank">PDF,</a>
                  
                  <a href="https://github.com/felixkreuk/UnsupSeg" target="_blank">Code</a>
                  ]
                
                <li id="paper"  class="mb-1"> <u>Felix Kreuk</u>, Yossi Adi, Bhiksha Raj, Rita Singh, Joseph Keshet. <b>Hide and Speak: Towards Deep Neural Networks for Speech Steganography</b>. <em>The 21st Annual Conference of the International Speech Communication Association (Interspeech), 2020</em> </li>
                  [
                  <a href="https://arxiv.org/pdf/1902.03083.pdf" target="_blank">PDF,</a>
                  
                  <a href="projects/steg/index.html" target="_blank">Samples,</a>
                  
                  <a href="https://github.com/felixkreuk/HideAndSpeak" target="_blank">Code</a>
                  ]
                
                <li id="paper"  class="mb-1"> Yuval Atzmon, <u>Felix Kreuk</u>, Uri Shalit, Gal Chechik. <b>A Causal View of Compositional Zero-Shot Recognition</b>. <em>The 34th Annual Conference on Neural Information Processing Systems (NeurIPS), 2020</em> </li>
                  [
                  <a href="https://arxiv.org/pdf/2006.14610.pdf" target="_blank">PDF</a>
                  ]
                
                <li id="paper"  class="mb-1"> <u>Felix Kreuk</u>, Yaniv Sheena, Joseph Keshet, Yossi Adi. <b>Phoneme Boundary Detection using Learnable Segmental Features</b>. <em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2020</em> </li>
                  [
                  <a href="https://arxiv.org/pdf/2002.04992.pdf" target="_blank">PDF,</a>
                  
                  <a href="https://github.com/felixkreuk/SegFeat" target="_blank">Code</a>
                  ]
                
                <li id="paper"  class="mb-1"> <u>Felix Kreuk</u>, Assi Barak, Shir Aviv-Reuven, Moran Baruch, Benny Pinkas, Joseph Keshet. <b>Deceiving End-to-End Deep Learning Malware Detectors using Adversarial Examples</b>. <em>Workshop track at 32nd Conference on Neural Information Processing Systems (NeurIPS), 2018</em> </li>
                  [
                  <a href="https://arxiv.org/pdf/1802.04528.pdf" target="_blank">PDF</a>
                  ]
                
                <li id="paper"  class="mb-1"> <u>Felix Kreuk</u>, Yossi Adi, Moustapha Cisse, Joseph Keshet. <b>Fooling End-to-end Speaker Verification by Adversarial Examples</b>. <em>IEEE International Conference in Acoustic, Speech and Signal Processing (ICASSP), 2018</em> </li>
                  [
                  <a href="https://arxiv.org/pdf/1801.03339.pdf" target="_blank">PDF</a>
                  ]
                
              </ol>
            </div>
          </div>                            
        </div>
			</div>
		</div>
	</div>
</section>

<!-- service section --> 
<!-- footer section -->
<footer class="footer">
  <div class="container">
    <div class="col-md-6 right">
      <p>© 2015 All rights reserved. All Rights Reserved<br>
        Made with <i class="fa fa-heart pulse"></i> by <a href="http://www.designstub.com/">Designstub</a></p>
    </div>
  </div>
</footer>
<!-- footer section --> 

<!-- JS FILES --> 
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script> 
<script src="js/bootstrap.min.js"></script> 
<script src="js/jquery.fancybox.pack.js"></script> 
<script src="js/retina.min.js"></script> 
<script src="js/modernizr.js"></script> 
<script src="js/main.js"></script>
</body>
</html>
